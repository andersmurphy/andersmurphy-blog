<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8" /><title>100000 TPS over a billion rows: the unreasonable effectiveness of SQLite</title><meta content="
base-uri        &apos;self&apos;;
form-action     &apos;self&apos;;
default-src     &apos;none&apos;;
script-src      &apos;self&apos;;
img-src         &apos;self&apos;;
font-src        &apos;self&apos;;
connect-src     &apos;self&apos;;
frame-src       https://example.andersmurphy.com https://checkboxes.andersmurphy.com https://www.youtube-nocookie.com;
style-src       &apos;self&apos; &apos;unsafe-inline&apos;
" http-equiv="Content-Security-Policy" /><meta content="text/html; charset=UTF-8" http-equiv="content-type" /><link href="/styles.css" rel="stylesheet" type="text/css" /><link href="/assets/favicon.png" rel="shortcut icon" /><link href="/feed.xml" rel="alternate" title="Blog Posts" type="application/rss+xml" /><script defer="defer" src="/toggle.js"></script><meta content="width=device-width, initial-scale=1.0" name="viewport" /><meta content="same-origin" name="view-transition" /><meta content="A blog mostly about Clojure programming" name="description" /></head><body><header class="nav-sticky-top container-fluid"><nav class="container"><ul><li><div class="linkify" style="align-items:center;display:flex;"><img alt="portrait" height="40px" src="/assets/avatar.png" style="image-rendering:pixelated;padding:4px;" width="40px" /><h1 style="margin-bottom:0;">anders murphy</h1><a aria-label="Home" href="/"></a></div></li></ul><ul><li><a aria-label="about" class="contrast no-chaos" href="/about"><svg height="28" style="margin-bottom:6px;margin-top:6px;" viewBox="0 0 24 24" width="28" xmlns="http://www.w3.org/2000/svg"><linearGradient id="gradient-horizontal"><stop offset="0%" stop-color="var(--color-stop-1)"></stop><stop offset="33%" stop-color="var(--color-stop-2)"></stop><stop offset="66%" stop-color="var(--color-stop-3)"></stop><stop offset="100%" stop-color="var(--color-stop-4)"></stop></linearGradient><path d="M11.95 18q.525 0 .888-.363t.362-.887t-.362-.888t-.888-.362t-.887.363t-.363.887t.363.888t.887.362m.05 4q-2.075 0-3.9-.788t-3.175-2.137T2.788 15.9T2 12t.788-3.9t2.137-3.175T8.1 2.788T12 2t3.9.788t3.175 2.137T21.213 8.1T22 12t-.788 3.9t-2.137 3.175t-3.175 2.138T12 22m.1-14.3q.625 0 1.088.4t.462 1q0 .55-.337.975t-.763.8q-.575.5-1.012 1.1t-.438 1.35q0 .35.263.588t.612.237q.375 0 .638-.25t.337-.625q.1-.525.45-.937t.75-.788q.575-.55.988-1.2t.412-1.45q0-1.275-1.037-2.087T12.1 6q-.95 0-1.812.4T8.975 7.625q-.175.3-.112.638t.337.512q.35.2.725.125t.625-.425q.275-.375.688-.575t.862-.2" fill="url(#gradient-horizontal)"></path></svg></a></li><li><a aria-label="Github" class="contrast no-chaos" href="https://github.com/andersmurphy"><svg class="icon" height="24" style="margin-bottom:6px;margin-top:6px;" viewBox="0 0 496 512" width="24" xmlns="http://www.w3.org/2000/svg"><linearGradient id="gradient-horizontal"><stop offset="0%" stop-color="var(--color-stop-1)"></stop><stop offset="33%" stop-color="var(--color-stop-2)"></stop><stop offset="66%" stop-color="var(--color-stop-3)"></stop><stop offset="100%" stop-color="var(--color-stop-4)"></stop></linearGradient><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z" fill="url(#gradient-horizontal)"></path></svg></a></li><li><a aria-label="RSS" class="contrast no-chaos" href="/feed.xml"><svg class="icon" height="24" style="margin-bottom:6px;margin-top:6px;" viewBox="0 0 16 16" width="24" xmlns="http://www.w3.org/2000/svg"><linearGradient id="gradient-horizontal"><stop offset="0%" stop-color="var(--color-stop-1)"></stop><stop offset="33%" stop-color="var(--color-stop-2)"></stop><stop offset="66%" stop-color="var(--color-stop-3)"></stop><stop offset="100%" stop-color="var(--color-stop-4)"></stop></linearGradient><path d="M2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2zm1.5 2.5c5.523 0 10 4.477 10 10a1 1 0 1 1-2 0 8 8 0 0 0-8-8 1 1 0 0 1 0-2m0 4a6 6 0 0 1 6 6 1 1 0 1 1-2 0 4 4 0 0 0-4-4 1 1 0 0 1 0-2m.5 7a1.5 1.5 0 1 1 0-3 1.5 1.5 0 0 1 0 3" fill="url(#gradient-horizontal)"></path></svg></a></li><li><div class="theme-toggle" id="toggle"><svg aria-hidden="true" class="icon theme-toggle__inner-moon" height="30" viewBox="0 0 32 32" width="30" xmlns="http://www.w3.org/2000/svg"><linearGradient id="gradient-horizontal"><stop offset="0%" stop-color="var(--color-stop-1)"></stop><stop offset="33%" stop-color="var(--color-stop-2)"></stop><stop offset="66%" stop-color="var(--color-stop-3)"></stop><stop offset="100%" stop-color="var(--color-stop-4)"></stop></linearGradient><path d="M27.5 11.5v-7h-7L16 0l-4.5 4.5h-7v7L0 16l4.5 4.5v7h7L16 32l4.5-4.5h7v-7L32 16l-4.5-4.5zM16 25.4a9.39 9.39 0 1 1 0-18.8 9.39 9.39 0 1 1 0 18.8z"></path><circle cx="16" cy="16" r="8.1"></circle></svg></div></li></ul></nav></header><main class="container"><article><hgroup><h1>100000 TPS over a billion rows: the unreasonable effectiveness of SQLite</h1><p><time datetime="2025-12-02T00:00:00+00:00">02 Dec 2025</time></p></hgroup><hr /><p>SQLite doesn't have MVCC! It only has a single writer! SQLite is for phones and mobile apps (and the occasional airliner)! For web servers use a proper database like Postgres! In this article I'll go over why  being embedded and a single writer are not deficiencies but actually allow SQLite to scale so unreasonably well.</p><h2 id="prelude">Prelude</h2><p>For the code examples I will be using Clojure. But, what they cover should be applicable to most programming language.</p><p>The machine these benchmarks run on has the following specs:</p><ul><li>MacBook Pro (2021)</li><li>Chip: Apple M1 Pro</li><li>Memory: 16 GB</li></ul><p>These benchmarks are not meant to be perfect or even optimal. They are merely to illustrate that it's relatively easy to achieve decent write throughput with SQLite. Usual benchmark disclaimers apply. </p><h2 id="defining_tps">Defining TPS</h2><p>When I say TPS I don't mean writes/updates per second. I'm talking about transactions per second, specifically interactive transactions that are common when building web applications. By interactive transactions I mean transactions where you execute some queries, run some application code and then execute more queries. For example:</p><pre><code class="SQL">BEGIN;
UPDATE accounts SET balance = balance - 100.00
    WHERE name = 'Alice';
-- some application code runs
UPDATE accounts SET balance = balance + 100.00
    WHERE name = 'Bob';
COMMIT;
</code></pre><p>Transactions are useful because they let you rollback the state of your changes if your application encounters a problem.</p><h2 id="the_benchmark_harness">The benchmark harness</h2><p>To simulate requests we spin up <code>n</code> virtual threads (green threads) that each execute a function <code>f</code> this is analogous to handlers on a web server and will give us similar contention. Worth noting that this is high burst. I.e we will reach <code>n</code> level concurrent requests as fast as the system can spin up the virtual threads.</p><pre><code class="clojure"><span class="dim">&#40;</span>defmacro <strong>tx-per-second</strong> &#91;n &amp; body&#93;
  `<span class="dim">&#40;</span>let &#91;ids#   <span class="dim">&#40;</span>range 0 &#126;n<span class="dim">&#41;</span>
         start# <span class="dim">&#40;</span>. System <span class="dim">&#40;</span>nanoTime<span class="dim">&#41;&#41;</span>&#93;
     <span class="dim">&#40;</span>-&gt;&gt; ids#
       <span class="dim">;; Futures are using virtual threads so blocking is not slow
</span>       <span class="dim">&#40;</span>mapv <span class="dim">&#40;</span>fn &#91;&#95;#&#93; <span class="dim">&#40;</span>future &#126;@body<span class="dim">&#41;&#41;&#41;</span>
       <span class="dim">&#40;</span>run! deref<span class="dim">&#41;&#41;</span>
     <span class="dim">&#40;</span>int <span class="dim">&#40;</span>/ &#126;n <span class="dim">&#40;</span>/ <span class="dim">&#40;</span>double <span class="dim">&#40;</span>- <span class="dim">&#40;</span>. System <span class="dim">&#40;</span>nanoTime<span class="dim">&#41;&#41;</span> start#<span class="dim">&#41;&#41;</span> 1000000000.0<span class="dim">&#41;&#41;&#41;&#41;&#41;</span>
</code></pre><p>For the Clojure programmers among you <code>future</code> has been altered to use virtual threads. So, we can spin up millions if we need to.</p><pre><code class="clojure"><span class="dim">;; Make futures use virtual threads
</span><span class="dim">&#40;</span>set-agent-send-executor!
  <span class="dim">&#40;</span>Executors/newVirtualThreadPerTaskExecutor<span class="dim">&#41;&#41;</span>
<span class="dim">&#40;</span>set-agent-send-off-executor!
  <span class="dim">&#40;</span>Executors/newVirtualThreadPerTaskExecutor<span class="dim">&#41;&#41;</span>
</code></pre><p>We'll be using Postgres  as our network database (I'm using Postgres, but the same applies to MySQL etc) with a high performance connection pool optimised for our number of cores. </p><pre><code class="clojure"><span class="dim">&#40;</span>defonce <strong>pg-db</strong>
  <span class="dim">&#40;</span>jdbc/with-options
    <span class="dim">&#40;</span>connection/-&gt;pool
      HikariDataSource
      {:dbtype          &quot;postgres&quot;
       :dbname          &quot;thedb&quot;
       :username        <span class="dim">&#40;</span>System/getProperty &quot;user.name&quot;<span class="dim">&#41;</span>
       :password        &quot;&quot;
       :minimumIdle     8
       :maximumPoolSize 8}<span class="dim">&#41;</span>
    {}<span class="dim">&#41;&#41;</span>
</code></pre><p>We'll be using SQLite with a single writer connection and a number of reader connections equal to our number of cores.</p><pre><code class="clojure"><span class="dim">&#40;</span>defonce <strong>lite-db</strong>
  <span class="dim">&#40;</span>d/init-db! &quot;database.db&quot;
    {:pool-size 8
     :pragma {:cache&#95;size         15625
              :page&#95;size          4096
              :journal&#95;mode       &quot;WAL&quot;
              :synchronous        &quot;NORMAL&quot;
              :temp&#95;store         &quot;MEMORY&quot;
              :busy&#95;timeout       5000}}<span class="dim">&#41;&#41;</span>
</code></pre><p>Our databases will have a simple schema:</p><pre><code class="clojure"><span class="dim">&#40;</span>jdbc/execute! pg-db
  &#91;&quot;CREATE TABLE IF NOT EXISTS account<span class="dim">&#40;</span>id INT PRIMARY KEY, balance INT<span class="dim">&#41;</span>&quot;&#93;<span class="dim">&#41;</span>
<span class="dim">&#40;</span>d/q <span class="dim">&#40;</span>lite-db :writer<span class="dim">&#41;</span>
  &#91;&quot;CREATE TABLE IF NOT EXISTS account<span class="dim">&#40;</span>id PRIMARY KEY, balance INT<span class="dim">&#41;</span>&quot;&#93;<span class="dim">&#41;</span>
</code></pre><p>And each contain a billion rows:</p><pre><code class="clojure"><span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>range 0 <span class="dim">&#40;</span>&#42; 1000 1000 1000<span class="dim">&#41;&#41;</span>
  <span class="dim">&#40;</span>partition-all 32000<span class="dim">&#41;</span>
  <span class="dim">&#40;</span>run!
    <span class="dim">&#40;</span>fn &#91;batch&#93;
      <span class="dim">&#40;</span>jdbc-sql/insert-multi! pg-db :account
        <span class="dim">&#40;</span>mapv <span class="dim">&#40;</span>fn &#91;id&#93; {:id id :balance 1000000000}<span class="dim">&#41;</span> batch<span class="dim">&#41;&#41;&#41;&#41;&#41;</span>
        
<span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>range 0 <span class="dim">&#40;</span>&#42; 1000 1000 1000<span class="dim">&#41;&#41;</span>
  <span class="dim">&#40;</span>partition-all 100000<span class="dim">&#41;</span>
  <span class="dim">&#40;</span>run!
    <span class="dim">&#40;</span>fn &#91;batch&#93;
      <span class="dim">&#40;</span>d/with-write-tx &#91;tx <span class="dim">&#40;</span>lite-db :writer<span class="dim">&#41;</span>&#93;
        <span class="dim">&#40;</span>run!
          <span class="dim">&#40;</span>fn &#91;id&#93;
            <span class="dim">&#40;</span>d/q tx
              &#91;&quot;INSERT INTO account<span class="dim">&#40;</span>id, balance<span class="dim">&#41;</span> VALUES <span class="dim">&#40;</span>?,?<span class="dim">&#41;</span>&quot; id 1000000000&#93;<span class="dim">&#41;&#41;</span>
          batch<span class="dim">&#41;&#41;&#41;&#41;&#41;</span>
</code></pre><p>Our user distribution will follow a <a href='https://en.wikipedia.org/wiki/Power_law'>power law</a>. I.e the top X percent will be involved in most of the transactions. We have a billion users, so in practice most of those won't be active, or be active rarely. <code>0.9995</code> means 99.95% of transactions will be done by 0.05% of users. This still means around 100000 unique active users at any given time. </p><p>The reason we are using a power law, is that's a very common distribution for a lot of real products. If you think about a credit card payment system, in the context of retail, the largest number of transactions are most likely with a few large retailers (Amazon, Walmart etc).</p><pre><code class="clojure"><span class="dim">&#40;</span>defn <strong>pareto-user</strong> &#91;&#93;
  <span class="dim">&#40;</span>rand-pareto <span class="dim">&#40;</span>&#42; 1000 1000 1000<span class="dim">&#41;</span> 0.9995<span class="dim">&#41;&#41;</span>
</code></pre><p><code>rand-pareto</code> turns a random distribution into a power law distribution.</p><pre><code class="clojure"><span class="dim">&#40;</span>defn <strong>rand-pareto</strong> &#91;r p&#93;
  <span class="dim">&#40;</span>let &#91;a <span class="dim">&#40;</span>/ <span class="dim">&#40;</span>Math/log <span class="dim">&#40;</span>- 1.0 p<span class="dim">&#41;&#41;</span> <span class="dim">&#40;</span>Math/log p<span class="dim">&#41;&#41;</span>
        x <span class="dim">&#40;</span>rand<span class="dim">&#41;</span>
        y <span class="dim">&#40;</span>/ <span class="dim">&#40;</span>- <span class="dim">&#40;</span>+ <span class="dim">&#40;</span>Math/pow x a<span class="dim">&#41;</span> 1.0<span class="dim">&#41;</span>
               <span class="dim">&#40;</span>Math/pow <span class="dim">&#40;</span>- 1.0 x<span class="dim">&#41;</span> <span class="dim">&#40;</span>/ 1.0 a<span class="dim">&#41;&#41;&#41;</span>
            2.0<span class="dim">&#41;</span>&#93;
    <span class="dim">&#40;</span>long <span class="dim">&#40;</span>&#42; r y<span class="dim">&#41;&#41;&#41;&#41;</span>
</code></pre><h2 id="network_database">Network database</h2><p>Let's start with a network database.</p><pre><code class="clojure"><span class="dim">&#40;</span>tx-per-second 100000
  <span class="dim">&#40;</span>jdbc/with-transaction &#91;tx pg-db&#93;
    <span class="dim">&#40;</span>jdbc/execute! tx <span class="dim">&#40;</span>credit-random-account<span class="dim">&#41;&#41;</span>
    <span class="dim">&#40;</span>jdbc/execute! tx <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;&#41;&#41;</span>
    
<span class="dim">;; =&gt; 13756 TPS
</span></code></pre><p>A respectable 13756 TPS.</p><p>However, normally a network database will not be on the same server as our application. So let's simulate some network latency. Let's say you have 5ms latency between your app server and your database.</p><pre><code class="clojure"><span class="dim">&#40;</span>tx-per-second 10000
  <span class="dim">&#40;</span>jdbc/with-transaction &#91;tx pg-db&#93;
    <span class="dim">&#40;</span>jdbc/execute! tx <span class="dim">&#40;</span>credit-random-account<span class="dim">&#41;&#41;</span>
    <span class="dim">&#40;</span>Thread/sleep 5<span class="dim">&#41;</span>
    <span class="dim">&#40;</span>jdbc/execute! tx <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;&#41;&#41;</span>
    
<span class="dim">;; =&gt; 1214 TPS
</span></code></pre><p><em>Note: virtual threads do not sleep a real thread. They instead park allowing the underlying carrier thread to resume another virtual thread.</em></p><p>What if we increase that latency to 10ms?</p><pre><code class="clojure"><span class="dim">&#40;</span>tx-per-second 10000
  <span class="dim">&#40;</span>jdbc/with-transaction &#91;tx pg-db&#93;
    <span class="dim">&#40;</span>jdbc/execute! tx <span class="dim">&#40;</span>credit-random-account<span class="dim">&#41;&#41;</span>
    <span class="dim">&#40;</span>Thread/sleep 10<span class="dim">&#41;</span>
    <span class="dim">&#40;</span>jdbc/execute! tx <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;&#41;&#41;</span>
    
<span class="dim">;; =&gt; 702 TPS
</span></code></pre><p>But, wait our transactions are not serialisable, which they need to be if we want consistent transaction processing (SQLite is isolation serialisable by design). We better fix that and handle retries.</p><pre><code class="clojure"><span class="dim">&#40;</span>tx-per-second 10000
  <span class="dim">&#40;</span>loop &#91;&#93;
    <span class="dim">&#40;</span>let &#91;result
          <span class="dim">&#40;</span>try
            <span class="dim">&#40;</span>jdbc/with-transaction &#91;tx pg-db {:isolation :serializable}&#93;
              <span class="dim">&#40;</span>jdbc/execute! tx <span class="dim">&#40;</span>credit-random-account<span class="dim">&#41;&#41;</span>
              <span class="dim">&#40;</span>Thread/sleep 10<span class="dim">&#41;</span>
              <span class="dim">&#40;</span>jdbc/execute! tx  <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;&#41;</span>
            <span class="dim">&#40;</span>catch Exception &#95; nil<span class="dim">&#41;&#41;</span>&#93;
      <span class="dim">&#40;</span>when-not result <span class="dim">&#40;</span>recur<span class="dim">&#41;&#41;&#41;&#41;&#41;</span>

<span class="dim">;; =&gt; 660 TPS
</span></code></pre><p>What if the interactive transaction has an extra query (an extra network hop)?</p><pre><code class="clojure"><span class="dim">&#40;</span>tx-per-second 10000
  <span class="dim">&#40;</span>loop &#91;&#93;
    <span class="dim">&#40;</span>let &#91;result
          <span class="dim">&#40;</span>try
            <span class="dim">&#40;</span>jdbc/with-transaction &#91;tx pg-db {:isolation :serializable}&#93;
              <span class="dim">&#40;</span>jdbc/execute! tx <span class="dim">&#40;</span>credit-random-account<span class="dim">&#41;&#41;</span>
              <span class="dim">&#40;</span>Thread/sleep 10<span class="dim">&#41;</span>
              <span class="dim">&#40;</span>jdbc/execute! tx  <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;</span>
              <span class="dim">&#40;</span>Thread/sleep 10<span class="dim">&#41;</span>
              <span class="dim">&#40;</span>jdbc/execute! tx  <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;&#41;</span>
            <span class="dim">&#40;</span>catch Exception &#95; nil<span class="dim">&#41;&#41;</span>&#93;
      <span class="dim">&#40;</span>when-not result <span class="dim">&#40;</span>recur<span class="dim">&#41;&#41;&#41;&#41;&#41;</span>

<span class="dim">;; =&gt; 348 TPS
</span></code></pre><p>348 TPS! What's going on here? <a href='https://en.wikipedia.org/wiki/Amdahl%27s_law'>Amdahl's Law</a> strikes!</p><blockquote><p>the overall performance improvement gained by optimizing a single part of a system is limited by the fraction of time that the improved part is actually used. </p></blockquote><p>We're holding transactions with row locks across a network with high contention because of the power law. What's terrifying about this is no amount of additional (cpu/servers/memory) is going to save us. This is a hard limit caused by the network. What's worse, in any unexpected increase in latency will exacerbate the problem. Which also means you can't have application servers in different data centres than your database (because of the increased latency). </p><p>I learnt this the hard way building an emoji based tipping bot for discord. At the time I didn't understand why we were hitting this hard limit in TPS. We ended up sacrificing the convenience of interactive transactions and moving everything into stored procedures (meaning no locks across the network). However, in a lot of domains this isn't possible.</p><h2 id="embedded_means_no_network">Embedded means no network</h2><p>Let's see how SQLite fares.</p><pre><code class="clojure"><span class="dim">&#40;</span>tx-per-second 1000000
  <span class="dim">&#40;</span>d/with-write-tx &#91;tx <span class="dim">&#40;</span>lite-db :writer<span class="dim">&#41;</span>&#93;
    <span class="dim">&#40;</span>d/q tx <span class="dim">&#40;</span>credit-random-account<span class="dim">&#41;&#41;</span>
    <span class="dim">&#40;</span>d/q tx <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;&#41;&#41;</span>

<span class="dim">;; =&gt; 44096 TPS
</span></code></pre><p>44096 TPS! By eliminating the network SQLite massively reduces the impact of Amdahl's law.</p><h2 id="single_writer_lets_you_batch_%28trivially%29">Single writer lets you batch (trivially)</h2><p>We don't need to stop there though. Because, SQLite is a single writer we can batch. <a href='https://github.com/andersmurphy/sqlite4clj'>sqlite4clj</a> provides a convenient dynamic batching function. Batch size grows dynamically with the workload and producers don't have to block when the consumer is busy. Effectively it self optimises for latency and throughput.</p><pre><code class="clojure"><span class="dim">&#40;</span>defn <strong>batch-fn</strong> &#91;db batch&#93;
  @<span class="dim">&#40;</span>on-pool! lite-write-pool
     <span class="dim">&#40;</span>d/with-write-tx &#91;tx db&#93;
       <span class="dim">&#40;</span>run! <span class="dim">&#40;</span>fn &#91;thunk&#93; <span class="dim">&#40;</span>thunk tx<span class="dim">&#41;&#41;</span> batch<span class="dim">&#41;&#41;&#41;&#41;</span>
       
<span class="dim">&#40;</span>defonce <strong>tx!</strong>
  <span class="dim">&#40;</span>b/async-batcher-init! lite-db
    {:batch-fn #'batch-fn}<span class="dim">&#41;&#41;</span>
</code></pre><p><em>Note: to Clojure/Java programmers we're using a thread pool as SQLite should be treated as CPU not IO, so we don't want it starving our virtual threads (io green threads).</em></p><pre><code class="clojure"><span class="dim">&#40;</span>tx-per-second 1000000
  @<span class="dim">&#40;</span>tx!
     <span class="dim">&#40;</span>fn &#91;tx&#93;
       <span class="dim">&#40;</span>d/q tx <span class="dim">&#40;</span>credit-random-account<span class="dim">&#41;&#41;</span>
       <span class="dim">&#40;</span>d/q tx <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;&#41;&#41;&#41;</span>
       
<span class="dim">;; =&gt; 186157 TPS
</span></code></pre><p>But, wait I hear you cry! That's cheating we now don't have isolated transaction failure. Batching is sacrificing fine grained transaction. You're right! Let's fix that.</p><pre><code class="clojure"><span class="dim">&#40;</span>tx-per-second 1000000
  @<span class="dim">&#40;</span>tx!
     <span class="dim">&#40;</span>fn  &#91;tx&#93;
       <span class="dim">&#40;</span>d/q tx &#91;&quot;SAVEPOINT inner&#95;tx&quot;&#93;<span class="dim">&#41;</span>
       <span class="dim">&#40;</span>try
         <span class="dim">&#40;</span>d/q tx <span class="dim">&#40;</span>credit-random-account<span class="dim">&#41;&#41;</span>
         <span class="dim">&#40;</span>d/q tx <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;</span>
         <span class="dim">&#40;</span>catch Throwable &#95;
           <span class="dim">&#40;</span>d/q tx &#91;&quot;ROLLBACK inner&#95;tx&quot;&#93;<span class="dim">&#41;&#41;&#41;</span>
       <span class="dim">&#40;</span>d/q tx &#91;&quot;RELEASE inner&#95;tx&quot;&#93;<span class="dim">&#41;&#41;&#41;&#41;</span>
       
<span class="dim">;; =&gt; 121922 TPS
</span></code></pre><p>SQLite supports nested transactions with <code>SAVEPOINT</code> this lets us have fine-grained transaction rollback whilst still batching our writes. If a transaction fails it won't cause the batch to fail. The only case where the whole batch will fail is in the case of power loss/or a hard crash.</p><h2 id="what_about_concurrent_reads%3F">What about concurrent reads?</h2><p>Generally systems have a mix of reads and writes, somewhere in the region of 75% reads to 25% writes. So let's add some writes.</p><pre><code class="clojure"><span class="dim">&#40;</span>tx-per-second 1000000
  <span class="dim">&#40;</span>on-pool! lite-read-pool
    <span class="dim">&#40;</span>d/q <span class="dim">&#40;</span>lite-db :reader<span class="dim">&#41;</span>
      &#91;&quot;select &#42; from account where id = ? limit 1&quot; <span class="dim">&#40;</span>pareto-user<span class="dim">&#41;</span>&#93;<span class="dim">&#41;&#41;</span>
  <span class="dim">&#40;</span>on-pool! lite-read-pool
    <span class="dim">&#40;</span>d/q <span class="dim">&#40;</span>lite-db :reader<span class="dim">&#41;</span>
      &#91;&quot;select &#42; from account where id = ? limit 1&quot; <span class="dim">&#40;</span>pareto-user<span class="dim">&#41;</span>&#93;<span class="dim">&#41;&#41;</span>
  <span class="dim">&#40;</span>on-pool! lite-read-pool
    <span class="dim">&#40;</span>d/q <span class="dim">&#40;</span>lite-db :reader<span class="dim">&#41;</span>
      &#91;&quot;select &#42; from account where id = ? limit 1&quot; <span class="dim">&#40;</span>pareto-user<span class="dim">&#41;</span>&#93;<span class="dim">&#41;&#41;</span>
  @<span class="dim">&#40;</span>tx!
     <span class="dim">&#40;</span>fn  &#91;tx&#93;
       <span class="dim">&#40;</span>d/q tx &#91;&quot;SAVEPOINT inner&#95;tx&quot;&#93;<span class="dim">&#41;</span>
       <span class="dim">&#40;</span>try
         <span class="dim">&#40;</span>d/q tx <span class="dim">&#40;</span>credit-random-account<span class="dim">&#41;&#41;</span>
         <span class="dim">&#40;</span>d/q tx <span class="dim">&#40;</span>debit-random-account<span class="dim">&#41;&#41;</span>
         <span class="dim">&#40;</span>catch Throwable &#95;
           <span class="dim">&#40;</span>d/q tx &#91;&quot;ROLLBACK inner&#95;tx&quot;&#93;<span class="dim">&#41;&#41;&#41;</span>
       <span class="dim">&#40;</span>d/q tx &#91;&quot;RELEASE inner&#95;tx&quot;&#93;<span class="dim">&#41;&#41;&#41;&#41;</span>
       
<span class="dim">;; =&gt; 102545 TPS
</span></code></pre><p>102545 TPS!</p><p><em>Note: to Clojure/Java programmers we're using a separate read thread pool so that reads don't starve writes.</em></p><h2 id="tps_report">TPS Report</h2><table><thead><tr><th></th><th>Postgres</th><th>SQLite</th></tr></thead><tbody><tr><td>no network</td><td>13756</td><td>44096</td></tr><tr><td>5ms</td><td>1214</td><td>n/a</td></tr><tr><td>10ms</td><td>702</td><td>n/a</td></tr><tr><td>10ms serializable</td><td>660</td><td>n/a</td></tr><tr><td>batch</td><td>n/a</td><td>186157</td></tr><tr><td>batch savepoint</td><td>n/a</td><td>121922</td></tr><tr><td>batch savepoint + reads</td><td>n/a</td><td>102545</td></tr></tbody></table><h2 id="conclusion">Conclusion</h2><p>Hopefully, this post helps illustrate the unreasonable effectiveness of SQLite as well as the challenges you can run in with Amdahl's law and network databases like postgres.</p><p>The full benchmark code <a href='https://github.com/andersmurphy/clj-cookbook/tree/master/sqlite-vs-postgres'>can be found here</a>.</p><h2 id="epilogue">Epilogue</h2><h3 id="pragma_synchronous_%22full%22">Pragma synchronous  "FULL"</h3><p>Some <a href='https://news.ycombinator.com/item?id=46127511'>smart hackers on hackernnews</a> pointed out that using synchronous normal was not a fair comparison as technically under <a href='https://sqlite.org/pragma.html#pragma_synchronous'>some conditions is can sacrifice some durability</a>.</p><p>So here are the updated numbers.</p><table><thead><tr><th></th><th>Postgres</th><th>SQLite</th></tr></thead><tbody><tr><td>no network</td><td>13756</td><td>20654</td></tr><tr><td>5ms</td><td>1214</td><td>n/a</td></tr><tr><td>10ms</td><td>702</td><td>n/a</td></tr><tr><td>10ms serializable</td><td>660</td><td>n/a</td></tr><tr><td>batch</td><td>n/a</td><td>161868</td></tr><tr><td>batch savepoint</td><td>n/a</td><td>98163</td></tr><tr><td>batch savepoint + reads</td><td>n/a</td><td>100405</td></tr></tbody></table><p>Interestingly, you can see the power of dynamic batching here. The addition of concurrent reads means the batches have time to get larger so we have less writes and are therefore less impacted by <code>synchronous &quot;FULL&quot;</code>. This is why <code>batch savepoint</code> is slower than <code>batch savepoint + reads</code>.  What the numbers don't show is there will be a fractional latency increase.</p><h3 id="you_don%27t_need_isolation_serializable_%28you_really_do_for_a_ledger%29">You don't need isolation serializable (you really do for a ledger)</h3><p><a href='https://news.ycombinator.com/item?id=46126804'>Some comments on hackernew</a> argued you don't need isolation serializable. In the context of this example you very much do. But let's covers all the number. I've also added results for 1ms latency for those who wanted to see that.</p><table><thead><tr><th></th><th>Postgres</th><th>SQLite</th></tr></thead><tbody><tr><td>no net</td><td>13756</td><td>20654</td></tr><tr><td>1ms</td><td>5428</td><td>n/a</td></tr><tr><td>5ms</td><td>1214</td><td>n/a</td></tr><tr><td>10ms</td><td>702</td><td>n/a</td></tr><tr><td>no net serializable</td><td>10026</td><td>20654</td></tr><tr><td>1ms    serializable</td><td>4691</td><td>n/a</td></tr><tr><td>5ms    serializable</td><td>1182</td><td>n/a</td></tr><tr><td>10ms   serializable</td><td>660</td><td>n/a</td></tr><tr><td>batch</td><td>n/a</td><td>161868</td></tr><tr><td>batch savepoint</td><td>n/a</td><td>98163</td></tr><tr><td>batch savepoint + reads</td><td>n/a</td><td>100405</td></tr></tbody></table><h3 id="give_postgres_a_bigger_connection_pool%21">Give postgres a bigger connection pool!</h3><p><a href='https://news.ycombinator.com/item?id=46126662'>Some comments on hackernews</a> argued that increasing postgres' connection pool size to 64 would improve the numbers. It made some better and some worse (note there was a larger number of queries exceeding 30s and ability to handle burst was reduced). Serializable results became much worse.</p><table><thead><tr><th></th><th>Postgres</th><th>SQLite</th></tr></thead><tbody><tr><td>no net</td><td>17399</td><td>20654</td></tr><tr><td>1ms</td><td>8430</td><td>n/a</td></tr><tr><td>5ms</td><td>7563</td><td>n/a</td></tr><tr><td>10ms</td><td>5574</td><td>n/a</td></tr><tr><td>no net serializable</td><td>10283</td><td>20654</td></tr><tr><td>1ms    serializable</td><td>83</td><td>n/a</td></tr><tr><td>5ms    serializable</td><td>75</td><td>n/a</td></tr><tr><td>10ms   serializable</td><td>66</td><td>n/a</td></tr><tr><td>batch</td><td>n/a</td><td>161868</td></tr><tr><td>batch savepoint</td><td>n/a</td><td>98163</td></tr><tr><td>batch savepoint + reads</td><td>n/a</td><td>100405</td></tr></tbody></table><p>Also checkout <a href='https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing'>this article on connection pool sizing</a>.</p><h3 id="disclaimer%3A_there%27s_nothing_wrong_with_postgres">Disclaimer: There's nothing wrong with Postgres</h3><p>If you are not in the business of running on a single monolithic server. Or not confident handling backups. Or fully understand the nuances and limitations of SQLite DO NOT USE IT. There's nothing wrong with a managed postgres service.</p><p><strong>Further Reading:</strong></p><p>If you want to learn more about Amdahl's law, power laws and how they interact with network databases I highly recommend listening to <a href='https://www.youtube.com/watch?v=9oyhNDv882U'>this interview with Joran Greef</a> and watching his talk <a href='https://www.youtube.com/watch?v=yKgfk8lTQuE'>1000x: The Power of an Interface for Performance by Joran Dirk Greef</a>.   </p><p>If you want to read about how much further you can scale SQLite checkout <a href='https://use.expensify.com/blog/scaling-sqlite-to-4m-qps-on-a-single-server'>Scaling SQLite to 4M QPS on a single server (EC2 vs Bare Metal)</a>.</p><p>If you're thinking of running SQLite in production and wondering how to create streaming replicas, backups and projections checkout <a href='https://litestream.io'>litestream</a>.</p><p>If you still don't think a single machine can handle your workload it's worth reading <a href='https://www.usenix.org/system/files/conference/hotos15/hotos15-paper-mcsherry.pdf'>Scalability! But at what COST?</a>.</p><p><strong>Thanks to</strong> Everyone on the <a href='https://discord.gg/bnRNgZjgPh'>Datastar discord</a> who read drafts of this and gave me feedback.</p><p><strong>Discussion</strong></p><ul><li><a href='https://news.ycombinator.com/item?id=46124205'>hackernews</a></li><li><a href='https://www.reddit.com/r/Clojure/comments/1pchdr3/sqlite4clj_100k_tps_over_a_billion_rows_the/'>reddit</a></li></ul></article><footer><p>Â© 2015-2025 Anders Murphy</p></footer></main></body></html>