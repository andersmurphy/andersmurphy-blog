<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8" /><title>Clojure: website link checker</title><meta content="
base-uri    &apos;self&apos;;
form-action &apos;self&apos;;
default-src &apos;none&apos;;
script-src  &apos;self&apos;;
img-src     &apos;self&apos;;
font-src    &apos;self&apos;;
connect-src &apos;self&apos;;
style-src   &apos;self&apos;
" http-equiv="Content-Security-Policy" /><meta content="text/html; charset=UTF-8" http-equiv="content-type" /><link href="/styles.css" rel="stylesheet" type="text/css" /><link href="/assets/apple-touch-icon-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144" /><link href="/assets/favicon.ico" rel="shortcut icon" /><meta content="width=device-width, initial-scale=1.0" name="viewport" /><meta content="A blog mostly about software development." name="description" /></head><body><div class="sidebar"><div class="container sidebar-sticky"><div class="sidebar-about"><img alt="portrait" class="portrait" height="120" src="/assets/anderspixel.png" width="60" /><h1><a href="/">Anders Murphy</a></h1><p class="lead">A blog mostly about functional programming</p></div><nav class="sidebar-nav"><a class="sidebar-nav-item" href="https://github.com/andersmurphy">Github</a><a class="sidebar-nav-item" href="https://twitter.com/anders_murphy">Twitter</a><a class="sidebar-nav-item" href="https://uk.linkedin.com/in/anders-murphy-76457b3a">LinkedIn</a><a class="sidebar-nav-item" href="/feed.xml">RSS</a></nav></div></div><div class="content container"><article class="post"><h1 class="post-title">Clojure: website link checker</h1><time class="post-date" datetime="2021-10-31T00:00:00+00:00">31 Oct 2021</time><p>Writing a simple website link checker in Clojure for fun and profit. Clojure has this nifty function called <code>re-seq</code> that returns a lazy sequence of successive matches of a pattern in a string we can combine this with recursion to write a primitive website link checker.</p><p>First we write a function to find all the links on a given set of pages for a domain.</p><pre><code class="Clojure"><span class="dim">&#40;</span>defn <strong>get-all-links-on-pages</strong> &#91;domain pages&#93;
  <span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>filter #<span class="dim">&#40;</span>clojure.string/includes? % domain<span class="dim">&#41;</span> pages<span class="dim">&#41;</span>
       <span class="dim">&#40;</span>mapcat <span class="dim">&#40;</span>fn &#91;page&#93;
                 <span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>try <span class="dim">&#40;</span>slurp page<span class="dim">&#41;</span> <span class="dim">&#40;</span>catch Exception e &quot;&quot;<span class="dim">&#41;&#41;</span>
                      <span class="dim">&#40;</span>re-seq #&quot;href=&#91;\&quot;'&#93;<span class="dim">&#40;</span>.&#42;?<span class="dim">&#41;</span>&#91;\&quot;'&#93;&quot;<span class="dim">&#41;</span>
                      <span class="dim">&#40;</span>map second<span class="dim">&#41;&#41;&#41;&#41;&#41;&#41;</span>
</code></pre><p><code>&#40;filter #&#40;clojure.string/includes? % domain&#41; pages&#41;</code> prevents us slurping pages outside our domain (so that we don't end up crawling the whole internet). Because this function is only for gathering all the links on a page we don't care if a <code>slurp</code> fails so we guard against this with a <code>try ... catch</code>.</p><p>Next we write a recursive function to visit all links on a domain and continue following links within that domain until all have been <code>seen</code>.</p><pre><code class="Clojure"><span class="dim">&#40;</span>defn <strong>get-all-links-on-domain</strong>
  <span class="dim">&#40;</span>&#91;domain&#93; <span class="dim">&#40;</span>get-all-links-on-domain domain #{} &#91;domain&#93;<span class="dim">&#41;&#41;</span>
  <span class="dim">&#40;</span>&#91;domain seen links&#93;
   <span class="dim">&#40;</span>if <span class="dim">&#40;</span>seq links<span class="dim">&#41;</span>
     <span class="dim">&#40;</span>let &#91;seen <span class="dim">&#40;</span>into seen links<span class="dim">&#41;</span>&#93;
       <span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>get-all-links-on-pages domain links<span class="dim">&#41;</span>
            <span class="dim">&#40;</span>remove seen<span class="dim">&#41;</span>
            distinct
            <span class="dim">&#40;</span>recur domain seen<span class="dim">&#41;&#41;&#41;</span>
     seen<span class="dim">&#41;&#41;&#41;</span>
</code></pre><p>If we call this function we get a set of all the links on this domain (note this won't find orphaned pages).</p><pre><code class="Clojure"><span class="dim">&#40;</span>get-all-links-on-domain &quot;https://andersmurphy.com&quot;<span class="dim">&#41;</span>
<span class="dim">
=&gt;</span>
#{&quot;https://github.com/andersmurphy/clj-cookbook/tree/master/generating-files/html-and-xml-example&quot;
  &quot;https://andersmurphy.com/2020/08/20/emacs-setting-up-apheleia-to-use-zprint.html&quot;
  &quot;http://gallium.inria.fr/&#126;huet/PUBLIC/zip.pdf&quot;
  &quot;https://en.wikipedia.org/wiki/Open%E2%80%93closed&#95;principle&quot;
  &quot;https://brew.sh/&quot;
  ...}
</code></pre><p>This function takes just under 2 seconds to find all 149 links on this website.</p><pre><code class="Clojure"><span class="dim">&#40;</span>time <span class="dim">&#40;</span>count <span class="dim">&#40;</span>get-all-links-on-domain &quot;https://andersmurphy.com&quot;<span class="dim">&#41;&#41;&#41;</span>
<span class="dim">
=&gt;</span>
&quot;Elapsed time: 1753.119164 msecs&quot;

149
</code></pre><p>Not particularly slow, but we can make it faster by using <code>pmap</code>.</p><pre><code class="Clojure"><span class="dim">&#40;</span>defn <strong>get-all-links-on-pages</strong> &#91;domain pages&#93;
  <span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>filter #<span class="dim">&#40;</span>clojure.string/includes? % domain<span class="dim">&#41;</span> pages<span class="dim">&#41;</span>
       <span class="dim">&#40;</span>pmap <span class="dim">&#40;</span>fn &#91;page&#93;
               <span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>try <span class="dim">&#40;</span>slurp page<span class="dim">&#41;</span> <span class="dim">&#40;</span>catch Exception e &quot;&quot;<span class="dim">&#41;&#41;</span>
                    <span class="dim">&#40;</span>re-seq #&quot;href=&#91;\&quot;'&#93;<span class="dim">&#40;</span>.&#42;?<span class="dim">&#41;</span>&#91;\&quot;'&#93;&quot;<span class="dim">&#41;</span>
                    <span class="dim">&#40;</span>map second<span class="dim">&#41;&#41;&#41;&#41;</span>
       flatten<span class="dim">&#41;&#41;</span>
</code></pre><p>This is a simple way of processing each link in parallel.</p><pre><code class="Clojure"><span class="dim">&#40;</span>time <span class="dim">&#40;</span>count <span class="dim">&#40;</span>get-all-links-on-domain &quot;https://andersmurphy.com&quot;<span class="dim">&#41;&#41;&#41;</span>
<span class="dim">
=&gt;</span>
&quot;Elapsed time: 873.775003 msecs&quot;

149
</code></pre><p>To check the links we write a function that connects to the url and checks the response code (that way we don't do any additional processing of the data).</p><pre><code class="Clojure"><span class="dim">&#40;</span>defn <strong>check-link</strong> &#91;link&#93;
  <span class="dim">&#40;</span>when-not <span class="dim">&#40;</span>= <span class="dim">&#40;</span>try <span class="dim">&#40;</span>-&gt; <span class="dim">&#40;</span>clojure.java.io/as-url link<span class="dim">&#41;</span>
                        .openConnection
                        .getResponseCode<span class="dim">&#41;</span>
                    <span class="dim">&#40;</span>catch Exception e 404<span class="dim">&#41;&#41;</span>
               200<span class="dim">&#41;</span>
    link<span class="dim">&#41;&#41;</span>
</code></pre><p>Weaving all this together we get a primitive program for checking links on a domain.</p><pre><code class="Clojure"><span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>map check-link <span class="dim">&#40;</span>get-all-links-on-domain &quot;https://andersmurphy.com&quot;<span class="dim">&#41;&#41;</span>
       <span class="dim">&#40;</span>remove nil?<span class="dim">&#41;&#41;</span>
<span class="dim">
=&gt;</span>

<span class="dim">&#40;</span>&quot;https://andersmurphy.com/2017/12/28/desert-island-code-reduce-map-and-filter/&quot;
 &quot;https://github.com/andersmurphy/chain/commit/1afec87e14f609bd5c7deb6aff8c5a00774be92b&quot;
 &quot;https://github.com/clojure/math.combinatoricsh/&quot;
 &quot;http://proguard.sourceforge.net/&quot;
 &quot;https://en.wikipedia.org/wiki/Recursion&#95;<span class="dim">&#40;</span>computer&#95;science&quot;
 &quot;https://github.com/andersmurphy/chain/commit/9d2241a2a6d2571696a1d3ad5ba37e521d8641f5&quot;
 &quot;https://uk.linkedin.com/in/anders-murphy-76457b3a&quot;
 &quot;https://proguard.sourceforge.net/&quot;
 &quot;https://github.com/andersmurphy/chain/commit/4462327da5849f6ac7c4a41e290d84dc6f016b21&quot;
 &quot;https://github.com/andersmurphy/chain/commit/531597724d68cf27d6e9fdd2e88f54fe4082c841&quot;<span class="dim">&#41;</span>
</code></pre><p>Turns out there were broken links on this website!</p><p>This program is pretty slow and takes 40s to run. This is partly due to some of the external links having long load times.</p><pre><code class="Clojure"><span class="dim">&#40;</span>time
 <span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>map check-link <span class="dim">&#40;</span>get-all-links-on-domain &quot;https://andersmurphy.com&quot;<span class="dim">&#41;&#41;</span>
      <span class="dim">&#40;</span>remove nil?<span class="dim">&#41;</span>
      doall<span class="dim">&#41;&#41;</span><span class="dim">
=&gt;</span>
&quot;Elapsed time: 39476.81269 msecs&quot;

...
</code></pre><p>Again using <code>pmap</code> we can get some quick performance gains. Reducing our run time to 10s.</p><pre><code class="Clojure"><span class="dim">&#40;</span>time
 <span class="dim">&#40;</span>-&gt;&gt; <span class="dim">&#40;</span>pmap
       check-link
       <span class="dim">&#40;</span>get-all-links-on-domain &quot;https://andersmurphy.com&quot;<span class="dim">&#41;&#41;</span>
      <span class="dim">&#40;</span>remove nil?<span class="dim">&#41;</span>
      doall<span class="dim">&#41;&#41;</span>
<span class="dim">
=&gt;</span>
&quot;Elapsed time: 10484.143708 msecs&quot;

...
</code></pre><p>There are plenty of ways to improve the performance of this program. For example currently it performs two passes: gathering all the links and then checking them. There are also functional improvements like handling relative links etc. But they will be left as an exercise for the reader.</p><p>In this post we've seen how to use <code>slurp</code>, <code>re-seq</code>, <code>pmap</code> and recursion to write a basic link checker.</p></article><div class="footer"><p>Â© 2015-2024 Anders Murphy</p></div></div></body></html>